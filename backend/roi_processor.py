"""
ROI(Region of Interest) ì²˜ë¦¬ ëª¨ë“ˆ
ì˜ì–‘ì„±ë¶„í‘œ ì˜ì—­ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ì¶”ì¶œí•˜ì—¬ OCR ì¸ì‹ë¥ ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ëŠ¥
"""

import cv2
import numpy as np
from PIL import Image
import base64
import io
from typing import Tuple, List, Optional, Dict
import re


class ROIProcessor:
    """ì˜ì–‘ì„±ë¶„í‘œ ì˜ì—­ ê°ì§€ ë° ì¶”ì¶œì„ ìœ„í•œ ROI ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ROI í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”"""
        print("ğŸ” ROI í”„ë¡œì„¸ì„œë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
        
        # ì˜ì–‘ì„±ë¶„í‘œ ê´€ë ¨ í‚¤ì›Œë“œ (í•œêµ­ì–´/ì˜ì–´)
        self.nutrition_keywords = [
            'ì˜ì–‘ì„±ë¶„', 'ì˜ì–‘ì •ë³´', 'nutrition', 'nutrition facts',
            'ì¹¼ë¡œë¦¬', 'calories', 'kcal', 'ì—ë„ˆì§€', 'energy',
            'ë‹¨ë°±ì§ˆ', 'protein', 'íƒ„ìˆ˜í™”ë¬¼', 'carbohydrate', 'carb',
            'ì§€ë°©', 'fat', 'ë‚˜íŠ¸ë¥¨', 'sodium', 'ë‹¹ë¥˜', 'sugar',
            'í¬í™”ì§€ë°©', 'saturated', 'íŠ¸ëœìŠ¤ì§€ë°©', 'trans',
            'ì½œë ˆìŠ¤í…Œë¡¤', 'cholesterol', 'ì‹ì´ì„¬ìœ ', 'fiber'
        ]
        
        print("âœ… ROI í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def detect_nutrition_table_region(self, image: np.ndarray) -> Optional[Tuple[int, int, int, int]]:
        """
        ì´ë¯¸ì§€ì—ì„œ ì˜ì–‘ì„±ë¶„í‘œ ì˜ì—­ì„ ê°ì§€
        
        Args:
            image: OpenCV ì´ë¯¸ì§€ ë°°ì—´
            
        Returns:
            Tuple[int, int, int, int]: (x, y, width, height) ë˜ëŠ” None
        """
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            denoised = cv2.medianBlur(gray, 3)
            
            # ì—£ì§€ ê²€ì¶œ
            edges = cv2.Canny(denoised, 50, 150, apertureSize=3)
            
            # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì„  ì—°ê²°
            kernel = np.ones((3, 3), np.uint8)
            edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
            
            # ìœ¤ê³½ì„  ì°¾ê¸°
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # ì˜ì–‘ì„±ë¶„í‘œ í›„ë³´ ì˜ì—­ë“¤
            candidates = []
            
            for contour in contours:
                # ìœ¤ê³½ì„  ë©´ì  ê³„ì‚°
                area = cv2.contourArea(contour)
                if area < 1000:  # ë„ˆë¬´ ì‘ì€ ì˜ì—­ ì œì™¸
                    continue
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                x, y, w, h = cv2.boundingRect(contour)
                
                # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ í™•ì¸ (ì˜ì–‘ì„±ë¶„í‘œëŠ” ë³´í†µ ì„¸ë¡œê°€ ê¸´ ì§ì‚¬ê°í˜•)
                aspect_ratio = w / h
                if aspect_ratio < 0.3 or aspect_ratio > 3.0:  # ë„ˆë¬´ ê·¹ë‹¨ì ì¸ ë¹„ìœ¨ ì œì™¸
                    continue
                
                # ì˜ì—­ í¬ê¸° í™•ì¸ (ì´ë¯¸ì§€ì˜ ìµœì†Œ 5% ì´ìƒ)
                img_area = image.shape[0] * image.shape[1]
                if area < img_area * 0.05:
                    continue
                
                candidates.append({
                    'bbox': (x, y, w, h),
                    'area': area,
                    'aspect_ratio': aspect_ratio
                })
            
            if not candidates:
                return None
            
            # ê°€ì¥ í° ì˜ì—­ì„ ì„ íƒ (ì˜ì–‘ì„±ë¶„í‘œëŠ” ë³´í†µ í° ì˜ì—­)
            best_candidate = max(candidates, key=lambda x: x['area'])
            return best_candidate['bbox']
            
        except Exception as e:
            print(f"âŒ ì˜ì–‘ì„±ë¶„í‘œ ì˜ì—­ ê°ì§€ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def extract_roi_from_image(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> np.ndarray:
        """
        ì´ë¯¸ì§€ì—ì„œ ROI ì˜ì—­ ì¶”ì¶œ
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            bbox: (x, y, width, height) ë°”ìš´ë”© ë°•ìŠ¤
            
        Returns:
            np.ndarray: ì¶”ì¶œëœ ROI ì´ë¯¸ì§€
        """
        x, y, w, h = bbox
        
        # ê²½ê³„ í™•ì¸ ë° ì¡°ì •
        x = max(0, x)
        y = max(0, y)
        w = min(w, image.shape[1] - x)
        h = min(h, image.shape[0] - y)
        
        # ROI ì¶”ì¶œ
        roi = image[y:y+h, x:x+w]
        
        return roi
    
    def preprocess_roi(self, roi_image: np.ndarray) -> np.ndarray:
        """
        ROI ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (OCR ì¸ì‹ë¥  í–¥ìƒ)
        
        Args:
            roi_image: ROI ì´ë¯¸ì§€
            
        Returns:
            np.ndarray: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(roi_image.shape) == 3:
                gray = cv2.cvtColor(roi_image, cv2.COLOR_BGR2GRAY)
            else:
                gray = roi_image.copy()
            
            # ë…¸ì´ì¦ˆ ì œê±°
            denoised = cv2.medianBlur(gray, 3)
            
            # ëŒ€ë¹„ í–¥ìƒ (CLAHE ì ìš©)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            enhanced = clahe.apply(denoised)
            
            # ì´ì§„í™” (ì ì‘ì  ì„ê³„ê°’)
            binary = cv2.adaptiveThreshold(
                enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
            )
            
            # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì—°ê²°
            kernel = np.ones((2, 2), np.uint8)
            processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            
            return processed
            
        except Exception as e:
            print(f"âŒ ROI ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return roi_image
    
    def detect_text_regions_in_roi(self, roi_image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """
        ROI ë‚´ì—ì„œ í…ìŠ¤íŠ¸ ì˜ì—­ë“¤ì„ ê°ì§€
        
        Args:
            roi_image: ROI ì´ë¯¸ì§€
            
        Returns:
            List[Tuple[int, int, int, int]]: í…ìŠ¤íŠ¸ ì˜ì—­ë“¤ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            if len(roi_image.shape) == 3:
                gray = cv2.cvtColor(roi_image, cv2.COLOR_BGR2GRAY)
            else:
                gray = roi_image.copy()
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            
            # ì ì‘ì  ì„ê³„ê°’ìœ¼ë¡œ ì´ì§„í™”
            binary = cv2.adaptiveThreshold(
                blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2
            )
            
            # í…ìŠ¤íŠ¸ ì—°ê²°ì„ ìœ„í•œ ëª¨í´ë¡œì§€ ì—°ì‚°
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            dilated = cv2.dilate(binary, kernel, iterations=2)
            
            # ì—°ê²°ëœ ì»´í¬ë„ŒíŠ¸ ì°¾ê¸°
            contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            text_regions = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 100:  # ìµœì†Œ ë©´ì  í•„í„°ë§
                    x, y, w, h = cv2.boundingRect(contour)
                    text_regions.append((x, y, w, h))
            
            return text_regions
            
        except Exception as e:
            print(f"âŒ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def process_image_with_roi(self, image_data: str) -> Dict:
        """
        ì´ë¯¸ì§€ì—ì„œ ROIë¥¼ ì¶”ì¶œí•˜ê³  ì „ì²˜ë¦¬í•˜ì—¬ OCRì— ìµœì í™”ëœ ì´ë¯¸ì§€ ë°˜í™˜
        
        Args:
            image_data: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°
            
        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            # base64 ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            if image_data.startswith('data:'):
                image_base64 = image_data.split(',')[1]
            else:
                image_base64 = image_data
            
            # base64ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜
            image_bytes = base64.b64decode(image_base64)
            pil_image = Image.open(io.BytesIO(image_bytes))
            opencv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            
            # ì˜ì–‘ì„±ë¶„í‘œ ì˜ì—­ ê°ì§€
            bbox = self.detect_nutrition_table_region(opencv_image)
            
            if bbox is None:
                print("âš ï¸ ì˜ì–‘ì„±ë¶„í‘œ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                # ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©
                processed_image = self.preprocess_roi(opencv_image)
                roi_bbox = (0, 0, opencv_image.shape[1], opencv_image.shape[0])
            else:
                print(f"âœ… ì˜ì–‘ì„±ë¶„í‘œ ì˜ì—­ ê°ì§€: {bbox}")
                # ROI ì¶”ì¶œ
                roi_image = self.extract_roi_from_image(opencv_image, bbox)
                # ROI ì „ì²˜ë¦¬
                processed_image = self.preprocess_roi(roi_image)
                roi_bbox = bbox
            
            # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
            _, buffer = cv2.imencode('.jpg', processed_image)
            processed_base64 = base64.b64encode(buffer).decode('utf-8')
            
            return {
                'success': True,
                'processed_image': processed_base64,
                'roi_bbox': roi_bbox,
                'original_size': (opencv_image.shape[1], opencv_image.shape[0]),
                'processed_size': (processed_image.shape[1], processed_image.shape[0])
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ROI ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}',
                'processed_image': None,
                'roi_bbox': None
            }
    
    def enhance_nutrition_text_recognition(self, text: str) -> str:
        """
        ì˜ì–‘ì„±ë¶„ í…ìŠ¤íŠ¸ ì¸ì‹ë¥  í–¥ìƒì„ ìœ„í•œ í›„ì²˜ë¦¬
        
        Args:
            text: OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
            
        Returns:
            str: í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
        """
        try:
            # ì¼ë°˜ì ì¸ OCR ì˜¤ë¥˜ ìˆ˜ì •
            corrections = {
                'O': '0',  # ì˜ë¬¸ Oë¥¼ ìˆ«ì 0ìœ¼ë¡œ
                'l': '1',  # ì˜ë¬¸ lì„ ìˆ«ì 1ë¡œ
                'I': '1',  # ì˜ë¬¸ Ië¥¼ ìˆ«ì 1ë¡œ
                'S': '5',  # ì˜ë¬¸ Së¥¼ ìˆ«ì 5ë¡œ (íŠ¹ì • ì»¨í…ìŠ¤íŠ¸ì—ì„œ)
            }
            
            # ìˆ«ì íŒ¨í„´ ê°œì„ 
            enhanced_text = text
            
            # ì˜ì–‘ì„±ë¶„ í‚¤ì›Œë“œ ì£¼ë³€ì˜ ìˆ«ì íŒ¨í„´ ê°œì„ 
            for keyword in self.nutrition_keywords:
                pattern = f'{keyword}[\\s]*[\\d\\.]+'
                matches = re.finditer(pattern, enhanced_text, re.IGNORECASE)
                
                for match in matches:
                    original = match.group()
                    # ìˆ«ì ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê³  ì •ë¦¬
                    numbers = re.findall(r'[\d\.]+', original)
                    if numbers:
                        # ê°€ì¥ í° ìˆ«ìë¥¼ ì„ íƒ (ì˜ì–‘ì„±ë¶„ ê°’)
                        max_number = max(numbers, key=lambda x: float(x) if '.' in x else int(x))
                        enhanced_text = enhanced_text.replace(original, f'{keyword} {max_number}')
            
            return enhanced_text
            
        except Exception as e:
            print(f"âŒ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return text


